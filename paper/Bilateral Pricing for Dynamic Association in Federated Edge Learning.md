#### **Bilateral Pricing for Dynamic Association in Federated Edge Learning**

------

## 文章解决的问题

在 **联邦边缘学习 (FEL)** 中，存在以下挑战：

- **设备与服务器自利且资源受限**：不愿意无偿贡献算力/带宽，需要激励机制。
- **动态网络条件**：网络拥塞和不稳定导致能耗增加。
- **数据异构性 (non-IID)**：设备数据分布不同，合作效果差，导致模型性能下降。
- **现有研究不足**：大多只考虑单方面激励或聚类优化，忽视了系统效率与设备分组的耦合。

 因此，本文要解决 **如何同时激励设备和服务器参与，并在动态网络和数据异构环境下优化模型性能**。

------

## 作者提出的方案

 **双边定价机制 BENCH (Bilateral priciNg meCHanism)**，包括三大规则：

1. **奖励分配规则**（Reward Allocation Rule）
   - 基于 **Rubinstein 谈判模型**，设计设备和服务器之间的奖励分配方式。
   - 给出 **闭式解 (closed-form solution)**，保证达到 **Nash 均衡**，从而激励设备和服务器稳定参与。
2. **设备划分规则**（Device Partitioning Rule）
   - 基于 **关系图 (relationship graph)**，把相似设备划分到同一分组，减少 non-IID 数据对聚合的影响。
   - 使用 **模体度优化 (modularity-oriented Riemann manifold optimization)** 提高分组质量。
3. **边缘匹配规则**（Edge Matching Rule）
   - 基于 **Kuhn-Munkres 匹配算法 (匈牙利算法)**，将设备分组与边缘服务器进行最优匹配，减少系统通信成本和拥塞。
   - 动态调整以应对网络波动。



------

## 系统构成

- **边缘服务器层**
   多个边缘服务器部署在靠近用户的位置，负责本地聚合和与云端的交互，同时也是奖励机制的执行者。
- **移动设备层**
   移动设备分属于不同的分区，它们在本地进行模型训练，并与边缘服务器通信。
- **机制设计层**
   由 **奖励分配规则 (Reward allocation rule)**、**设备划分规则 (Device partition rule)**、**边缘匹配规则 (Edge matching rule)** 三个核心模块组成，这些规则共同作用于任务分配、激励机制和资源管理。

------

## 流程步骤

### （1）初始设备与服务器关联

- 系统首先建立 **初始关联矩阵 K**，描述设备与边缘服务器之间的初始连接情况。
- 同时构建 **邻接矩阵 A**，通过关系图刻画设备之间的相似性和交互频率，用于后续设备划分。

------

### （2）设备划分

- 基于邻接矩阵和模体度优化，设备被划分成多个分区。
- 每个分区内部的设备具有相似的数据分布或任务属性，从而缓解 **数据异构性 (non-IID)** 问题。
- 在这一阶段，系统利用 **Riemann 流形优化** 来保证划分结果在数学约束下最优。

------

### （3）边缘匹配

- 划分完成后，分区与边缘服务器之间需要建立新的匹配关系。
- 系统利用 **Kuhn-Munkres 匹配算法 (Hungarian Algorithm)** 计算最优匹配，目标是最小化通信成本并平衡负载。
- 在匹配过程中会考虑 **背景使用向量 h** 与 **拥塞权重向量 $\gamma$**，以反映不同服务器的实时网络状态和拥塞情况。
- 此时生成新的关联矩阵 K'，更新设备与边缘服务器的连接关系。

------

### （4）奖励分配

- 在任务预算 B 的约束下，系统需要在设备和服务器之间分配奖励。
- 系统利用 **Rubinstein 谈判模型** 进行双边博弈，推导出一个 **闭式解 (closed-form solution)**，保证奖励分配达到 **纳什均衡**，即没有任何一方有动力偏离策略。
- 奖励分配结果为：
  - $r_n^d$：支付给设备 n 的奖励，用于补偿计算和通信能耗。
  - $r_m^e$：支付给边缘服务器 m 的奖励，用于补偿调度与聚合开销。

------

### （5）训练与聚合

- 移动设备在本地数据集 $\mathcal{S}_n $上训练模型，更新本地参数 $\omega_m^n(t,\tau)$。
- 在边缘服务器处，聚合来自分区内设备的更新，得到新的边缘模型，再进一步上传到云端进行全局聚合。
- 聚合过程受控于：
  - 本地迭代次数 $\tilde{\tau}$
  - 边缘聚合轮数 $\tilde{t}$
- 最终实现全局模型参数 ω 的更新。

------

### （6）动态反馈与迭代

- 在每一轮联邦学习之后，系统会重新评估：
  - 设备的计算成本与能耗 ($\mathbf{C}, \tilde{C}_n$)
  - 网络带宽与信道条件 ($\varrho_{m,n}, d_{m,n}$)
  - 奖励分配结果是否满足公平性和预算约束
- 如果出现网络拥塞或设备退出，系统会通过 **Newton-Raphson 方法** 预测未来的拥塞成本，并动态调整匹配与奖励。
- 该过程不断迭代，保证在动态环境下系统性能持续优化。

------

 **总结**：
 BENCH 系统通过 **“设备划分 → 边缘匹配 → 奖励分配 → 动态迭代”** 的完整流程，形成了一个既考虑 **公平激励** 又兼顾 **性能优化** 的联邦边缘学习框架。


